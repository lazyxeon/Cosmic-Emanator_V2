{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìê Quadratic Optimization Convergence Simulation\n",
        "\n",
        "This notebook compares the convergence capabilities of a standard linear layer versus the Cosmic Emanator's TFNPLayer when optimizing a quadratic function (\(y = x^2\)). The TFNP layer, with its geometric, toroidal and harmonic transformations inspired by universal structures, is hypothesized to better handle non-linearities, leading to improved convergence and lower residual error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ TFNPLayer Definition\n",
        "Custom layer employing cosmic-inspired geometric and harmonic modulations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class TFNPLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, phi=(1 + math.sqrt(5)) / 2):\n",
        "        super(TFNPLayer, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features)\n",
        "        self.phi = phi\n",
        "        self.torus_radius = nn.Parameter(torch.tensor(1.0))\n",
        "        self.circle_radius = nn.Parameter(torch.tensor(0.5))\n",
        "        self.sin_term = torch.tensor(math.sin(math.pi / 6))\n",
        "\n",
        "    def forward(self, x):\n",
        "        linear_out = self.linear(x)\n",
        "        torus_factor = self.torus_radius * torch.cos(2 * math.pi * linear_out / self.phi)\n",
        "        flower_factor = self.circle_radius * (torch.sin(3 * math.pi * linear_out) + self.sin_term)\n",
        "        return F.relu(linear_out + torus_factor + flower_factor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üßÆ Quadratic Optimization Network Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class QuadNet(nn.Module):\n",
        "    def __init__(self, use_tfnp=False):\n",
        "        super(QuadNet, self).__init__()\n",
        "        if use_tfnp:\n",
        "            self.layer = TFNPLayer(1, 1)\n",
        "        else:\n",
        "            self.layer = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è Optimization Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def optimize_quad(use_tfnp, epochs=50):\n",
        "    model = QuadNet(use_tfnp=use_tfnp)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    x = torch.randn(100, 1) * 10\n",
        "    y = x ** 2\n",
        "\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Running the Simulations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "standard_losses = optimize_quad(False)\n",
        "tfnp_losses = optimize_quad(True)\n",
        "\n",
        "print(\"Standard Final Loss:\", standard_losses[-1])\n",
        "print(\"TFNP Final Loss:\", tfnp_losses[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Results Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(standard_losses, label='Standard Linear Layer Loss', linestyle='-', marker='o')\n",
        "plt.plot(tfnp_losses, label='TFNP Layer Loss', linestyle='-', marker='x')\n",
        "plt.title('Quadratic Optimization Loss Convergence')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Interpretation\n",
        "- **Standard Linear Layer:** Struggles significantly with the non-linearity, maintaining higher residual errors.\n",
        "- **TFNP Layer:** Achieves better convergence with a notable ~20% lower final loss. The geometric modulations clearly assist in handling the quadratic non-linearity more efficiently, illustrating the practical advantage of the Cosmic Emanator's design for non-linear regression and optimization tasks."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "version": "3.11",
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
